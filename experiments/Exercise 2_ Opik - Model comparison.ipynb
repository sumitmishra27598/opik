{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM87EYs+gl1dD5QhedZsp47"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bTq1QVQyUC-f","executionInfo":{"status":"ok","timestamp":1727016687860,"user_tz":-330,"elapsed":24573,"user":{"displayName":"Sumit Mishra","userId":"03876200325202187761"}},"outputId":"ce6db8dd-f979-4382-faa5-7a503ec4be12"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m580.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.5/185.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install --upgrade --quiet opik langchain langchain-community langchain-openai"]},{"cell_type":"code","source":["import opik\n","\n","opik.configure(use_local=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9dJBMgaUgKY","executionInfo":{"status":"ok","timestamp":1727016701071,"user_tz":-330,"elapsed":13220,"user":{"displayName":"Sumit Mishra","userId":"03876200325202187761"}},"outputId":"e9027898-6436-4ee3-b601-92cee30fb0ca"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["OPIK: Your Opik cloud API key is available at https://www.comet.com/api/my/settings/.\n"]},{"name":"stdout","output_type":"stream","text":["Please enter your Opik Cloud API key:··········\n","Do you want to use \"sumitmishra5504\" workspace? (Y/n)Y\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Saved configuration to a file: /root/.opik.config\n"]}]},{"cell_type":"code","source":["import os\n","import getpass\n","\n","if \"OPENAI_API_KEY\" not in os.environ:\n","    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8vNWiJJ-Wpe3","executionInfo":{"status":"ok","timestamp":1727016712537,"user_tz":-330,"elapsed":8045,"user":{"displayName":"Sumit Mishra","userId":"03876200325202187761"}},"outputId":"4e15c90b-3c34-49d1-cbe3-db67fbd8ab97"},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your OpenAI API key: ··········\n"]}]},{"cell_type":"markdown","source":["## Model 1: gpt-4o-mini"],"metadata":{"id":"aJkLY3-Xzk2z"}},{"cell_type":"code","source":["from opik import Opik, track, DatasetItem\n","from opik.evaluation import evaluate\n","from opik.evaluation.metrics import Equals, Hallucination\n","from opik.integrations.openai import track_openai\n","import openai\n","\n","# Define the task to evaluate\n","openai_client = track_openai(openai.OpenAI())\n","os.environ[\"OPIK_PROJECT_NAME\"] = \"opik-model-comparison\"\n","\n","MODEL = \"gpt-4o-mini\"\n","\n","from langchain_community.chat_models import ChatOpenAI\n","\n","llm = ChatOpenAI(\n","    model_name=MODEL,\n","    max_tokens=200\n",")\n","\n","@track(name=\"gpt_4o_mini_tracing\")\n","def get_sentiment(messages):\n","    return llm.invoke(messages).content\n","\n","def build_input_prompt(statement):\n","    user_content = f\"\"\"You will be provided a statement from twitter and your job is to determine sentiments of it. Sentiments should be below and just give sentiment as response.\n","    sentiments: [\"sadness\", \"happiness\", \"neutral\"]\n","\n","    Here is the statement.\n","    <statement>{statement}</statement>\n","\n","    What is the sentiment of statement? Please respond with a only one word. e.g. sadness\"\"\"\n","\n","    messages = [{'role': 'user', 'content': user_content}]\n","    return messages\n","\n","# Define the evaluation task\n","def evaluation_task(x: DatasetItem):\n","    return {\n","        \"input\": x.input['input'],\n","        \"output\": get_sentiment(build_input_prompt(x.input['input'])),\n","        \"expected_output\": x.expected_output['golden_answer']\n","    }\n","\n","# Create a simple dataset\n","client = Opik()\n","dataset = client.get_dataset(name=\"Sentiment Dataset\")\n","\n","# Define the metrics\n","from opik.evaluation.metrics import ContextPrecision, ContextRecall\n","\n","metric1 = ContextPrecision()\n","metric2 = ContextRecall()\n","\n","evaluation = evaluate(\n","    experiment_name=\"gpt-4o-mini comp\",\n","    dataset=dataset,\n","    task=evaluation_task,\n","    scoring_metrics=[metric1, metric2],\n","    experiment_config={\n","        \"model\": MODEL\n","    }\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249},"id":"4JjWUpLvzb_h","executionInfo":{"status":"ok","timestamp":1727016735900,"user_tz":-330,"elapsed":7552,"user":{"displayName":"Sumit Mishra","userId":"03876200325202187761"}},"outputId":"f0cfe845-ad0d-4484-dec1-6348027f6b9b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-6fc8c785aace>:15: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n","  llm = ChatOpenAI(\n","Evaluation: 100%|██████████| 20/20 [00:05<00:00,  3.72it/s]\n"]},{"output_type":"display_data","data":{"text/plain":["╭─ Sentiment Dataset (20 samples) ───────╮\n","│                                        │\n","│ \u001b[1mTotal time:       \u001b[0m 00:00:05            │\n","│ \u001b[1mNumber of samples:\u001b[0m 20                  │\n","│                                        │\n","│ \u001b[1;32mcontext_precision_metric: 0.4200 (avg)\u001b[0m │\n","│ \u001b[1;32mcontext_recall_metric: 0.6650 (avg)\u001b[0m    │\n","│                                        │\n","╰────────────────────────────────────────╯\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ Sentiment Dataset (20 samples) ───────╮\n","│                                        │\n","│ <span style=\"font-weight: bold\">Total time:       </span> 00:00:05            │\n","│ <span style=\"font-weight: bold\">Number of samples:</span> 20                  │\n","│                                        │\n","│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">context_precision_metric: 0.4200 (avg)</span> │\n","│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">context_recall_metric: 0.6650 (avg)</span>    │\n","│                                        │\n","╰────────────────────────────────────────╯\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Uploading results to Opik \u001b[33m...\u001b[0m \n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading results to Opik <span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Model 2: claude-3-sonnet-20240229"],"metadata":{"id":"SrylBHaR25mI"}},{"cell_type":"code","source":["ClaudeapiKey = getpass.getpass(\"Enter your Claude API key: \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"br_PRBgzOQs2","executionInfo":{"status":"ok","timestamp":1727016844818,"user_tz":-330,"elapsed":22570,"user":{"displayName":"Sumit Mishra","userId":"03876200325202187761"}},"outputId":"7fecc795-7492-49e3-f519-56603ded2ae1"},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Claude API key: ··········\n"]}]},{"cell_type":"code","source":["from opik import Opik, track, DatasetItem\n","from opik.evaluation import evaluate\n","from opik.evaluation.metrics import Equals, Hallucination\n","from opik.integrations.openai import track_openai\n","import openai\n","import urllib\n","import json\n","\n","# Define the task to evaluate\n","openai_client = track_openai(openai.OpenAI())\n","os.environ[\"OPIK_PROJECT_NAME\"] = \"opik-model-comparison\"\n","\n","MODEL = \"claude-3-sonnet-20240229\"\n","\n","def get_sentiment(messages):\n","    \"\"\"Make an API call to the Anthropic Claude model.\"\"\"\n","    url = \"https://api.anthropic.com/v1/messages\"\n","    headers = {\n","        'x-api-key': ClaudeapiKey,\n","        'anthropic-version': '2023-06-01',\n","        'content-type': 'application/json'\n","    }\n","    data = json.dumps({\n","        \"model\": \"claude-3-sonnet-20240229\",\n","        \"max_tokens\": 200,\n","        \"messages\": messages\n","    }).encode('utf-8')\n","\n","    req = urllib.request.Request(url, data=data, headers=headers, method='POST')\n","\n","    try:\n","        with urllib.request.urlopen(req) as response:\n","            output = response.read()\n","            return json.loads(output)['content'][0]['text']\n","    except urllib.error.HTTPError as e:\n","        print(f\"HTTP error: {e.code} - {e.reason}\")\n","        print(f\"Response body: {e.read().decode()}\")\n","\n","def build_input_prompt(statement):\n","    user_content = f\"\"\"You will be provided a statement from twitter and your job is to determine sentiments of it. Sentiments should be below and just give sentiment as response.\n","    sentiments: [\"sadness\", \"happiness\", \"neutral\"]\n","\n","    Here is the statement.\n","    <statement>{statement}</statement>\n","\n","    What is the sentiment of statement? Please respond with a only one word. e.g. sadness\"\"\"\n","\n","    messages = [{'role': 'user', 'content': user_content}]\n","    return messages\n","\n","@track(name=\"claude_3_sonnet_20240229_tracing\")\n","def get_sentiment(messages):\n","    return llm.invoke(messages).content\n","\n","def build_input_prompt(statement):\n","    user_content = f\"\"\"You will be provided a statement from twitter and your job is to determine sentiments of it. Sentiments should be below and just give sentiment as response.\n","    sentiments: [\"sadness\", \"happiness\", \"neutral\"]\n","\n","    Here is the statement.\n","    <statement>{statement}</statement>\n","\n","    What is the sentiment of statement? Please respond with a only one word. e.g. sadness\"\"\"\n","\n","    messages = [{'role': 'user', 'content': user_content}]\n","    return messages\n","\n","# Define the evaluation task\n","def evaluation_task(x: DatasetItem):\n","    return {\n","        \"input\": x.input['input'],\n","        \"output\": get_sentiment(build_input_prompt(x.input['input'])),\n","        \"expected_output\": x.expected_output['golden_answer']\n","    }\n","\n","# Create a simple dataset\n","client = Opik()\n","dataset = client.get_dataset(name=\"Sentiment Dataset\")\n","\n","# Define the metrics\n","from opik.evaluation.metrics import ContextPrecision, ContextRecall\n","\n","metric1 = ContextPrecision()\n","metric2 = ContextRecall()\n","\n","evaluation = evaluate(\n","    experiment_name=\"claude-3-sonnet-20240229 comp\",\n","    dataset=dataset,\n","    task=evaluation_task,\n","    scoring_metrics=[metric1, metric2],\n","    experiment_config={\n","        \"model\": MODEL\n","    }\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":194},"id":"lsIU4LYrO2qh","executionInfo":{"status":"ok","timestamp":1727017225122,"user_tz":-330,"elapsed":8362,"user":{"displayName":"Sumit Mishra","userId":"03876200325202187761"}},"outputId":"aee117a2-d9e1-4a38-8d1b-d70f75304d97"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluation: 100%|██████████| 20/20 [00:06<00:00,  3.15it/s]\n"]},{"output_type":"display_data","data":{"text/plain":["╭─ Sentiment Dataset (20 samples) ───────╮\n","│                                        │\n","│ \u001b[1mTotal time:       \u001b[0m 00:00:06            │\n","│ \u001b[1mNumber of samples:\u001b[0m 20                  │\n","│                                        │\n","│ \u001b[1;32mcontext_precision_metric: 0.4700 (avg)\u001b[0m │\n","│ \u001b[1;32mcontext_recall_metric: 0.6450 (avg)\u001b[0m    │\n","│                                        │\n","╰────────────────────────────────────────╯\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ Sentiment Dataset (20 samples) ───────╮\n","│                                        │\n","│ <span style=\"font-weight: bold\">Total time:       </span> 00:00:06            │\n","│ <span style=\"font-weight: bold\">Number of samples:</span> 20                  │\n","│                                        │\n","│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">context_precision_metric: 0.4700 (avg)</span> │\n","│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">context_recall_metric: 0.6450 (avg)</span>    │\n","│                                        │\n","╰────────────────────────────────────────╯\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Uploading results to Opik \u001b[33m...\u001b[0m \n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading results to Opik <span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"6tvVEjoDP2gy"},"execution_count":null,"outputs":[]}]}